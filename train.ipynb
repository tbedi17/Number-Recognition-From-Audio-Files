{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ყველა ფაილის მისამართის ამოღება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: librosa in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.7.2)\n",
      "Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (2.1.8)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: resampy>=0.2.2 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.21.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.12 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.14.0)\n",
      "Requirement already satisfied, skipping upgrade: numba>=0.43.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.47.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.3 in /home/tamar/.local/lib/python3.7/site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: soundfile>=0.9.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (41.2.0)\n",
      "Requirement already satisfied, skipping upgrade: llvmlite>=0.31.0dev0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /home/tamar/.local/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa) (1.12.3)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /home/tamar/.local/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n",
      "Requirement already up-to-date: pydub in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.23.1)\n",
      "Requirement already up-to-date: pip in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (20.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade librosa\n",
    "!pip install --upgrade pydub\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio ფაილების გადაყვანა wav-ში"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color =green>extract_features ვარგა. ქვემოთ რაც წერია ყველაფერს სწორად შვება</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = get_mfcc(audio, sample_rate)\n",
    "        flux = get_spectral_features(audio, sample_rate)[2]\n",
    "#         zero_crossing_rate = get_zero_crossing_rate(audio)\n",
    "#         spectral_features = get_spectral_features(audio, sample_rate)\n",
    "        chroma_features = get_chroma_features(audio, sample_rate)\n",
    "        return [mfccs, flux] + chroma_features\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(folder):\n",
    "    folders = os.listdir(folder)\n",
    "    folders.sort()\n",
    "    all_features = []\n",
    "    for label, sub_dir in enumerate(folders): #label {0; 4}\n",
    "        for file_name in glob.glob(os.getcwd() + '/' + folder +'/' + sub_dir + '/*.wav'):\n",
    "#             print(\"Extracting file \", file_name)\n",
    "            try:\n",
    "                features = get_features(file_name)\n",
    "            except Exception as e:\n",
    "                print(\"Extraction error\")\n",
    "                continue\n",
    "            all_features.append(features +  [label + 1])\n",
    "    data = pd.DataFrame(all_features, columns=['mfccs', 'flux', 'chroma_features1', 'chroma_features2', 'chroma_features3', 'class_label'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(audio, sr):\n",
    "    #Mel Frequency Cepstral Coefficient\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=100)\n",
    "    mfccs_scaled = np.mean(mfccs.T,axis=0)\n",
    "#     mfccs - (40, სხვადასხვა), mfccsscaled - (40,)\n",
    "    return mfccs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_crossing_rate(audio):\n",
    "    #ZERO_CROSSING_RATE\n",
    "    rate = librosa.feature.zero_crossing_rate(audio)\n",
    "    rate_scaled = np.mean(rate.T,axis=0)\n",
    "#     rate - (1, სხვადასხვა)\n",
    "    return rate_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_features(audio, sr):\n",
    "    sp = librosa.feature.spectral_centroid(audio)\n",
    "    S, phase = librosa.magphase(librosa.stft(audio))\n",
    "    a = librosa.feature.spectral_rolloff(S=S, sr=sr)\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "    onset_env.shape = (onset_env.shape[0], 1)\n",
    "    sp_scaled = np.mean(sp.T,axis=0)\n",
    "    a_scaled = np.mean(a.T,axis=0)\n",
    "    onset_env_scaled = np.mean(onset_env,axis=0)\n",
    "    return [sp_scaled, a_scaled, onset_env_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma_features(audio, sr):    \n",
    "    # Chroma features (needs scaling)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr) #N1\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio, sr=sr) #Chroma energy normalized statistics\n",
    "    chroma_cq = librosa.feature.chroma_cqt(y=audio, sr=sr)\n",
    "#     samive - (12, სხვადასხვა)\n",
    "    chroma_stft_scaled = np.mean(chroma_stft.T,axis=0)\n",
    "    chroma_cens_scaled = np.mean(chroma_cens.T,axis=0)\n",
    "    chroma_cq_scaled = np.mean(chroma_cq.T,axis=0)\n",
    "    return [chroma_stft_scaled, chroma_cens_scaled, chroma_cq_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(audio, sr):\n",
    "    # Pitch (needs scaling)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)\n",
    "#     pitches - (1025, სხვადასხვა)\n",
    "    pitches_scaled = np.mean(pitches.T,axis=0)\n",
    "    return pitches_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = get_all_features('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfccs</th>\n",
       "      <th>flux</th>\n",
       "      <th>chroma_features1</th>\n",
       "      <th>chroma_features2</th>\n",
       "      <th>chroma_features3</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-563.3512, 83.42768, 15.9913845, 30.378, 7.49...</td>\n",
       "      <td>[1.2877665]</td>\n",
       "      <td>[0.490593, 0.43263522, 0.41713786, 0.4319621, ...</td>\n",
       "      <td>[0.23855104703452865, 0.19339022133616926, 0.1...</td>\n",
       "      <td>[0.48419195, 0.3967417, 0.36660203, 0.4046905,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-415.62613, 129.10883, 0.38149676, -2.560156,...</td>\n",
       "      <td>[1.1878353]</td>\n",
       "      <td>[0.4505017, 0.45908153, 0.4559908, 0.46738443,...</td>\n",
       "      <td>[0.3696895725371677, 0.290672106573877, 0.2328...</td>\n",
       "      <td>[0.7234272, 0.64493823, 0.57561886, 0.61767435...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-414.80673, 65.71164, 11.970185, 18.030397, -...</td>\n",
       "      <td>[1.5477084]</td>\n",
       "      <td>[0.42241085, 0.34647024, 0.3099448, 0.28886437...</td>\n",
       "      <td>[0.3662726855089679, 0.30184172312762186, 0.29...</td>\n",
       "      <td>[0.6762588, 0.59152263, 0.60965645, 0.51682824...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-476.1924, 98.35074, 9.049427, 53.071404, 16....</td>\n",
       "      <td>[1.4277123]</td>\n",
       "      <td>[0.5276107, 0.37308845, 0.4098288, 0.495738, 0...</td>\n",
       "      <td>[0.2701955494926417, 0.2612967298830713, 0.282...</td>\n",
       "      <td>[0.51186836, 0.50900024, 0.5152791, 0.55262387...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[-625.66, 95.10185, 2.4537098, 18.509094, -0.6...</td>\n",
       "      <td>[1.5897195]</td>\n",
       "      <td>[0.6447596, 0.49822325, 0.38547748, 0.3440539,...</td>\n",
       "      <td>[0.44987373492421207, 0.38843743780735224, 0.2...</td>\n",
       "      <td>[0.84486204, 0.74459755, 0.61213535, 0.571984,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>933</td>\n",
       "      <td>[-559.1015, 33.033833, -1.5776844, 13.724551, ...</td>\n",
       "      <td>[0.8792078]</td>\n",
       "      <td>[0.39154282, 0.37308574, 0.35078266, 0.3753931...</td>\n",
       "      <td>[0.3320585565879884, 0.2361567213514251, 0.212...</td>\n",
       "      <td>[0.6149197, 0.5404739, 0.46294823, 0.517493, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>934</td>\n",
       "      <td>[-604.3167, 83.39328, 17.018976, 37.68737, 14....</td>\n",
       "      <td>[1.1346732]</td>\n",
       "      <td>[0.49363038, 0.4740044, 0.42214367, 0.42252132...</td>\n",
       "      <td>[0.3074319749999116, 0.28517516190292935, 0.17...</td>\n",
       "      <td>[0.57406163, 0.4965746, 0.36137938, 0.31753466...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>[-255.2281, 83.4614, 12.161046, 33.219982, 2.5...</td>\n",
       "      <td>[1.25909]</td>\n",
       "      <td>[0.48128998, 0.43248865, 0.42360225, 0.4463603...</td>\n",
       "      <td>[0.2321763687080916, 0.23501861178036354, 0.27...</td>\n",
       "      <td>[0.547936, 0.5541493, 0.6068322, 0.6248768, 0....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>936</td>\n",
       "      <td>[-524.3405, 91.013084, -12.496176, 20.460442, ...</td>\n",
       "      <td>[1.8563066]</td>\n",
       "      <td>[0.42336696, 0.41790977, 0.38771373, 0.3419288...</td>\n",
       "      <td>[0.40768162973538374, 0.3649610190863246, 0.33...</td>\n",
       "      <td>[0.7123892, 0.6882575, 0.6068655, 0.57250977, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>937</td>\n",
       "      <td>[-571.8401, 77.63891, -1.7756209, 24.193274, -...</td>\n",
       "      <td>[1.1431836]</td>\n",
       "      <td>[0.41285264, 0.424501, 0.49278346, 0.3578849, ...</td>\n",
       "      <td>[0.2939707161578868, 0.32094654053894023, 0.29...</td>\n",
       "      <td>[0.63271016, 0.645237, 0.6383068, 0.56627864, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>938 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mfccs         flux  \\\n",
       "0    [-563.3512, 83.42768, 15.9913845, 30.378, 7.49...  [1.2877665]   \n",
       "1    [-415.62613, 129.10883, 0.38149676, -2.560156,...  [1.1878353]   \n",
       "2    [-414.80673, 65.71164, 11.970185, 18.030397, -...  [1.5477084]   \n",
       "3    [-476.1924, 98.35074, 9.049427, 53.071404, 16....  [1.4277123]   \n",
       "4    [-625.66, 95.10185, 2.4537098, 18.509094, -0.6...  [1.5897195]   \n",
       "..                                                 ...          ...   \n",
       "933  [-559.1015, 33.033833, -1.5776844, 13.724551, ...  [0.8792078]   \n",
       "934  [-604.3167, 83.39328, 17.018976, 37.68737, 14....  [1.1346732]   \n",
       "935  [-255.2281, 83.4614, 12.161046, 33.219982, 2.5...    [1.25909]   \n",
       "936  [-524.3405, 91.013084, -12.496176, 20.460442, ...  [1.8563066]   \n",
       "937  [-571.8401, 77.63891, -1.7756209, 24.193274, -...  [1.1431836]   \n",
       "\n",
       "                                      chroma_features1  \\\n",
       "0    [0.490593, 0.43263522, 0.41713786, 0.4319621, ...   \n",
       "1    [0.4505017, 0.45908153, 0.4559908, 0.46738443,...   \n",
       "2    [0.42241085, 0.34647024, 0.3099448, 0.28886437...   \n",
       "3    [0.5276107, 0.37308845, 0.4098288, 0.495738, 0...   \n",
       "4    [0.6447596, 0.49822325, 0.38547748, 0.3440539,...   \n",
       "..                                                 ...   \n",
       "933  [0.39154282, 0.37308574, 0.35078266, 0.3753931...   \n",
       "934  [0.49363038, 0.4740044, 0.42214367, 0.42252132...   \n",
       "935  [0.48128998, 0.43248865, 0.42360225, 0.4463603...   \n",
       "936  [0.42336696, 0.41790977, 0.38771373, 0.3419288...   \n",
       "937  [0.41285264, 0.424501, 0.49278346, 0.3578849, ...   \n",
       "\n",
       "                                      chroma_features2  \\\n",
       "0    [0.23855104703452865, 0.19339022133616926, 0.1...   \n",
       "1    [0.3696895725371677, 0.290672106573877, 0.2328...   \n",
       "2    [0.3662726855089679, 0.30184172312762186, 0.29...   \n",
       "3    [0.2701955494926417, 0.2612967298830713, 0.282...   \n",
       "4    [0.44987373492421207, 0.38843743780735224, 0.2...   \n",
       "..                                                 ...   \n",
       "933  [0.3320585565879884, 0.2361567213514251, 0.212...   \n",
       "934  [0.3074319749999116, 0.28517516190292935, 0.17...   \n",
       "935  [0.2321763687080916, 0.23501861178036354, 0.27...   \n",
       "936  [0.40768162973538374, 0.3649610190863246, 0.33...   \n",
       "937  [0.2939707161578868, 0.32094654053894023, 0.29...   \n",
       "\n",
       "                                      chroma_features3  class_label  \n",
       "0    [0.48419195, 0.3967417, 0.36660203, 0.4046905,...            2  \n",
       "1    [0.7234272, 0.64493823, 0.57561886, 0.61767435...            3  \n",
       "2    [0.6762588, 0.59152263, 0.60965645, 0.51682824...            3  \n",
       "3    [0.51186836, 0.50900024, 0.5152791, 0.55262387...            1  \n",
       "4    [0.84486204, 0.74459755, 0.61213535, 0.571984,...            5  \n",
       "..                                                 ...          ...  \n",
       "933  [0.6149197, 0.5404739, 0.46294823, 0.517493, 0...            2  \n",
       "934  [0.57406163, 0.4965746, 0.36137938, 0.31753466...            1  \n",
       "935  [0.547936, 0.5541493, 0.6068322, 0.6248768, 0....            2  \n",
       "936  [0.7123892, 0.6882575, 0.6068655, 0.57250977, ...            1  \n",
       "937  [0.63271016, 0.645237, 0.6383068, 0.56627864, ...            5  \n",
       "\n",
       "[938 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "labels = [[i] for i in data['class_label']]\n",
    "# testLabels = [[i] for i in testData['class_label']]\n",
    "y_train = np.array(labels)\n",
    "# y_test = np.array(testLabels)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(data, np.array(labels), test_size=0.1, random_state = 127)\n",
    "# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def get_one_hot(y):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y_onehot = encoder.fit_transform(y)\n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_onehot_train = get_one_hot(y_train)\n",
    "# y_onehot_test = get_one_hot(y_test)\n",
    "# print(y_onehot_train.shape, y_onehot_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X):\n",
    "    # normalize the features\n",
    "    X = (X - X.mean()) / X.std()\n",
    "    \n",
    "    # compute the covariance matrix\n",
    "    X = np.matrix(X)\n",
    "    cov = (X.T * X) / X.shape[0]\n",
    "    \n",
    "    # perform SVD\n",
    "    U, S, V = np.linalg.svd(cov)\n",
    "    \n",
    "    return U, S, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_data(X, U, k):\n",
    "    U_reduced = U[:,:k]\n",
    "    return np.dot(X, U_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_data(Z, U, k):\n",
    "    U_reduced = U[:,:k]\n",
    "    return np.dot(Z, U_reduced.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# აქ გვინდა რომ ყველა ფიჩერზე გვქონდეს წვდომა და მაგიტომ ამოღებისას უნდა შევცვალოთ როგორცაა შენახული დანარჩენი არაფრის შეცვლა არ მოგვიწევს"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_X(x):\n",
    "    X = x.drop(columns=['class_label'])\n",
    "    X = X.values\n",
    "    ls = [] #featurebi gvinda da magitom\n",
    "    for i in range(X.shape[0]):\n",
    "        features = []\n",
    "        for j in range(X.shape[1]):\n",
    "            for k in X[i][j]:\n",
    "                features.append(k)\n",
    "        ls.append(features)\n",
    "    res = np.array(ls)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_train = get_processed_X(data)\n",
    "# ls_test = get_processed_X(x_test)\n",
    "# print(ls_train.shape, ls_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "U, S, V = pca(ls_train)\n",
    "ls_train = project_data(ls_train, U, k)\n",
    "# U1, S1, V1 = pca(ls_test)\n",
    "# ls_test = project_data(ls_test, U, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # ნეირონული ქსელის კოდი"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def softmax(z):\n",
    "    z_exp = [math.exp(i) for i in z]\n",
    "    sum_z_exp = sum(z_exp)\n",
    "    return [i / sum_z_exp for i in z_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    z3 = a2 * theta2.T\n",
    "    h = []\n",
    "    for i in range(z3.shape[0]):\n",
    "        z = [z3[i, j] for j in range(z3.shape[1])]\n",
    "        h.append(softmax(z))\n",
    "    h = np.array(h)\n",
    "#     h = sigmoid(z3)\n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "\n",
    "#     J = (-1 / m) * np.sum(y * np.log(h).T) #softmax\n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    J = cost(params,input_size, hidden_size, num_labels, X, y, learning_rate)\n",
    "\n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # add the gradient regularization term\n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 138), (5, 51))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = ls_train.shape[1]\n",
    "hidden_size = 50\n",
    "num_labels = y_onehot_train.shape[1]\n",
    "learning_rate = 1.5\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "ls_train = np.matrix(ls_train)\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15250609 0.15289431 0.27439777 0.12768066 0.29252117]\n",
      " [0.14599048 0.15563719 0.29197557 0.1225629  0.28383385]\n",
      " [0.17978844 0.14240967 0.25264439 0.14636093 0.27879657]\n",
      " ...\n",
      " [0.16436099 0.14735485 0.28918515 0.13282196 0.26627705]\n",
      " [0.18182933 0.14617203 0.23706371 0.15215176 0.28278317]\n",
      " [0.16325215 0.14806253 0.25028404 0.13888739 0.29951388]]\n",
      "2.5973425518830657\n"
     ]
    }
   ],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(ls_train, theta1, theta2)\n",
    "a1.shape, z2.shape, a2.shape, z3.shape, h.shape\n",
    "print(h)\n",
    "print(cost(params, input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5973425518830657, (7155,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 1.6572454689019034\n",
       "     jac: array([ 0.00000000e+00,  5.02506198e-04, -1.43815894e-05, ...,\n",
       "       -2.03581561e-05, -1.72767354e-04, -8.91064641e-05])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 300\n",
       "     nit: 36\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([-0.06890189,  0.31423388, -0.00899329, ..., -0.01272643,\n",
       "       -0.10803719, -0.05572124])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate), \n",
    "                method='TNC', jac=True, options={'maxiter': 300})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_train = np.matrix(ls_train)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(ls_train, theta1, theta2)\n",
    "y_pred_train = np.array(np.argmax(h, axis=1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = []\n",
    "thetas.append(theta1)\n",
    "thetas.append(theta2)\n",
    "np.save('weights', thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_test = np.matrix(ls_test)\n",
    "\n",
    "# a1, z2, a2, z3, h = forward_propagate(ls_test, theta1, theta2)\n",
    "# y_pred = np.array(np.argmax(h, axis=1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6748400852878464\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred_train, y_train)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y_test)]\n",
    "# accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
