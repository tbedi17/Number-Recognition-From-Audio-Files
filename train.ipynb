{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ყველა ფაილის მისამართის ამოღება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: librosa in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.7.2)\n",
      "Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (2.1.8)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.3 in /home/tamar/.local/lib/python3.7/site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: numba>=0.43.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.47.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.21.3)\n",
      "Requirement already satisfied, skipping upgrade: soundfile>=0.9.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied, skipping upgrade: resampy>=0.2.2 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.12 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.14.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (41.2.0)\n",
      "Requirement already satisfied, skipping upgrade: llvmlite>=0.31.0dev0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /home/tamar/.local/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa) (1.12.3)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /home/tamar/.local/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: pydub in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.23.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |██                              | 92kB 499kB/s eta 0:00:03\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 313, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/home/tamar/.local/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1822, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/home/tamar/.local/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1622, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 425, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 507, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/http/client.py\", line 457, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/http/client.py\", line 501, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 326, in recv_into\n",
      "    raise timeout(\"The read operation timed out\")\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/commands/install.py\", line 382, in run\n",
      "    resolver.resolve(requirement_set)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/legacy_resolve.py\", line 201, in resolve\n",
      "    self._resolve_one(requirement_set, req)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/legacy_resolve.py\", line 365, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/legacy_resolve.py\", line 313, in _get_abstract_dist_for\n",
      "    req, self.session, self.finder, self.require_hashes\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/operations/prepare.py\", line 194, in prepare_linked_requirement\n",
      "    progress_bar=self.progress_bar\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/download.py\", line 465, in unpack_url\n",
      "    progress_bar=progress_bar\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/download.py\", line 316, in unpack_http_url\n",
      "    progress_bar)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/download.py\", line 551, in _download_http_url\n",
      "    _download_url(resp, link, content_file, hashes, progress_bar)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/download.py\", line 253, in _download_url\n",
      "    hashes.check_against_chunks(downloaded_chunks)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/utils/hashes.py\", line 80, in check_against_chunks\n",
      "    for chunk in chunks:\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/download.py\", line 223, in written_chunks\n",
      "    for chunk in chunks:\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/utils/ui.py\", line 160, in iter\n",
      "    for x in it:\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_internal/download.py\", line 212, in resp_read\n",
      "    decode_content=False):\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 564, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 529, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 430, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade librosa\n",
    "!pip install --upgrade pydub\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio ფაილების გადაყვანა wav-ში"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color =green>extract_features ვარგა. ქვემოთ რაც წერია ყველაფერს სწორად შვება</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = get_mfcc(audio, sample_rate)\n",
    "        flux = get_spectral_features(audio, sample_rate)[2]\n",
    "#         zero_crossing_rate = get_zero_crossing_rate(audio)\n",
    "#         spectral_features = get_spectral_features(audio, sample_rate)\n",
    "        chroma_features = get_chroma_features(audio, sample_rate)\n",
    "        return [mfccs, flux] + chroma_features\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(folder):\n",
    "    folders = os.listdir(folder)\n",
    "    folders.sort()\n",
    "    all_features = []\n",
    "    for label, sub_dir in enumerate(folders): #label {0; 4}\n",
    "        for file_name in glob.glob(os.getcwd() + '/' + folder +'/' + sub_dir + '/*.wav'):\n",
    "#             print(\"Extracting file \", file_name)\n",
    "            try:\n",
    "                features = get_features(file_name)\n",
    "            except Exception as e:\n",
    "                print(\"Extraction error\")\n",
    "                continue\n",
    "            all_features.append(features +  [label + 1])\n",
    "    data = pd.DataFrame(all_features, columns=['mfccs', 'flux', 'chroma_features1', 'chroma_features2', 'chroma_features3', 'class_label'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(audio, sr):\n",
    "    #Mel Frequency Cepstral Coefficient\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=80)\n",
    "    mfccs_scaled = np.mean(mfccs.T,axis=0)\n",
    "#     mfccs - (40, სხვადასხვა), mfccsscaled - (40,)\n",
    "    return mfccs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_crossing_rate(audio):\n",
    "    #ZERO_CROSSING_RATE\n",
    "    rate = librosa.feature.zero_crossing_rate(audio)\n",
    "    rate_scaled = np.mean(rate.T,axis=0)\n",
    "#     rate - (1, სხვადასხვა)\n",
    "    return rate_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_features(audio, sr):\n",
    "    sp = librosa.feature.spectral_centroid(audio)\n",
    "    S, phase = librosa.magphase(librosa.stft(audio))\n",
    "    a = librosa.feature.spectral_rolloff(S=S, sr=sr)\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "    onset_env.shape = (onset_env.shape[0], 1)\n",
    "    sp_scaled = np.mean(sp.T,axis=0)\n",
    "    a_scaled = np.mean(a.T,axis=0)\n",
    "    onset_env_scaled = np.mean(onset_env,axis=0)\n",
    "    return [sp_scaled, a_scaled, onset_env_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma_features(audio, sr):    \n",
    "    # Chroma features (needs scaling)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr) #N1\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio, sr=sr) #Chroma energy normalized statistics\n",
    "    chroma_cq = librosa.feature.chroma_cqt(y=audio, sr=sr)\n",
    "#     samive - (12, სხვადასხვა)\n",
    "    chroma_stft_scaled = np.mean(chroma_stft.T,axis=0)\n",
    "    chroma_cens_scaled = np.mean(chroma_cens.T,axis=0)\n",
    "    chroma_cq_scaled = np.mean(chroma_cq.T,axis=0)\n",
    "    return [chroma_stft_scaled, chroma_cens_scaled, chroma_cq_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(audio, sr):\n",
    "    # Pitch (needs scaling)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)\n",
    "#     pitches - (1025, სხვადასხვა)\n",
    "    pitches_scaled = np.mean(pitches.T,axis=0)\n",
    "    return pitches_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = get_all_features('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfccs</th>\n",
       "      <th>flux</th>\n",
       "      <th>chroma_features1</th>\n",
       "      <th>chroma_features2</th>\n",
       "      <th>chroma_features3</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-406.3137, 90.07318, -17.52547, 19.188358, -4...</td>\n",
       "      <td>[1.2665296]</td>\n",
       "      <td>[0.50325, 0.43390477, 0.45751518, 0.55981123, ...</td>\n",
       "      <td>[0.2010815228001731, 0.17877661978133974, 0.13...</td>\n",
       "      <td>[0.41260996, 0.35917467, 0.3394772, 0.4229124,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-479.55746, 91.62016, 4.8111367, 45.4034, 7.1...</td>\n",
       "      <td>[2.0787861]</td>\n",
       "      <td>[0.710502, 0.6724909, 0.6182017, 0.53073376, 0...</td>\n",
       "      <td>[0.31813983391072426, 0.3531293189845657, 0.28...</td>\n",
       "      <td>[0.620216, 0.6951215, 0.61286265, 0.61554337, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-412.65436, 82.89575, -14.282551, -18.198072,...</td>\n",
       "      <td>[1.4700956]</td>\n",
       "      <td>[0.38203648, 0.32822415, 0.39516246, 0.3653528...</td>\n",
       "      <td>[0.2811999780220349, 0.3090476569723263, 0.313...</td>\n",
       "      <td>[0.5648398, 0.59924424, 0.63488513, 0.58711034...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-492.4508, 52.55787, -11.094436, 24.305426, -...</td>\n",
       "      <td>[1.2690605]</td>\n",
       "      <td>[0.35530308, 0.33277103, 0.35659152, 0.4583785...</td>\n",
       "      <td>[0.2933080292151442, 0.2664511925875559, 0.244...</td>\n",
       "      <td>[0.6027757, 0.57053393, 0.5303954, 0.58117336,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[-559.8948, 53.037304, 23.096941, 8.38059, 2.2...</td>\n",
       "      <td>[1.2796246]</td>\n",
       "      <td>[0.44477203, 0.36253828, 0.23909615, 0.2377628...</td>\n",
       "      <td>[0.38282826680034837, 0.3370629763078627, 0.25...</td>\n",
       "      <td>[0.6155926, 0.56290025, 0.47744942, 0.41551587...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>[-488.35214, 63.34991, 18.823492, 17.853516, -...</td>\n",
       "      <td>[0.9126781]</td>\n",
       "      <td>[0.39689508, 0.3515242, 0.34030342, 0.25555554...</td>\n",
       "      <td>[0.365042918727885, 0.3005016817024467, 0.2271...</td>\n",
       "      <td>[0.7129718, 0.5999869, 0.49596426, 0.4806125, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>684</td>\n",
       "      <td>[-647.4395, 53.12541, 14.57684, 29.460068, -3....</td>\n",
       "      <td>[1.3850218]</td>\n",
       "      <td>[0.62824255, 0.47224903, 0.32193753, 0.2552542...</td>\n",
       "      <td>[0.2849922771460006, 0.24627764286685888, 0.20...</td>\n",
       "      <td>[0.51113725, 0.50479937, 0.39885342, 0.5197480...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685</td>\n",
       "      <td>[-679.07196, 84.32127, 1.3979447, 10.759451, -...</td>\n",
       "      <td>[0.9670585]</td>\n",
       "      <td>[0.40746984, 0.45578644, 0.47212955, 0.4500661...</td>\n",
       "      <td>[0.29454657735332035, 0.27965101813545123, 0.2...</td>\n",
       "      <td>[0.61592126, 0.5651262, 0.5621043, 0.5231517, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>686</td>\n",
       "      <td>[-481.00757, 79.54055, 0.37326252, 19.646515, ...</td>\n",
       "      <td>[1.3181589]</td>\n",
       "      <td>[0.31452677, 0.2739423, 0.29177672, 0.23973174...</td>\n",
       "      <td>[0.31061829776123817, 0.2660416390428546, 0.27...</td>\n",
       "      <td>[0.62170583, 0.5375296, 0.56233233, 0.54323864...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>687</td>\n",
       "      <td>[-478.28024, 92.794464, -8.620884, 26.04683, 7...</td>\n",
       "      <td>[1.956133]</td>\n",
       "      <td>[0.52647233, 0.50926405, 0.48760957, 0.5163718...</td>\n",
       "      <td>[0.38839065712295284, 0.3523226336215788, 0.33...</td>\n",
       "      <td>[0.7167689, 0.7025457, 0.6690119, 0.6442276, 0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mfccs         flux  \\\n",
       "0    [-406.3137, 90.07318, -17.52547, 19.188358, -4...  [1.2665296]   \n",
       "1    [-479.55746, 91.62016, 4.8111367, 45.4034, 7.1...  [2.0787861]   \n",
       "2    [-412.65436, 82.89575, -14.282551, -18.198072,...  [1.4700956]   \n",
       "3    [-492.4508, 52.55787, -11.094436, 24.305426, -...  [1.2690605]   \n",
       "4    [-559.8948, 53.037304, 23.096941, 8.38059, 2.2...  [1.2796246]   \n",
       "..                                                 ...          ...   \n",
       "683  [-488.35214, 63.34991, 18.823492, 17.853516, -...  [0.9126781]   \n",
       "684  [-647.4395, 53.12541, 14.57684, 29.460068, -3....  [1.3850218]   \n",
       "685  [-679.07196, 84.32127, 1.3979447, 10.759451, -...  [0.9670585]   \n",
       "686  [-481.00757, 79.54055, 0.37326252, 19.646515, ...  [1.3181589]   \n",
       "687  [-478.28024, 92.794464, -8.620884, 26.04683, 7...   [1.956133]   \n",
       "\n",
       "                                      chroma_features1  \\\n",
       "0    [0.50325, 0.43390477, 0.45751518, 0.55981123, ...   \n",
       "1    [0.710502, 0.6724909, 0.6182017, 0.53073376, 0...   \n",
       "2    [0.38203648, 0.32822415, 0.39516246, 0.3653528...   \n",
       "3    [0.35530308, 0.33277103, 0.35659152, 0.4583785...   \n",
       "4    [0.44477203, 0.36253828, 0.23909615, 0.2377628...   \n",
       "..                                                 ...   \n",
       "683  [0.39689508, 0.3515242, 0.34030342, 0.25555554...   \n",
       "684  [0.62824255, 0.47224903, 0.32193753, 0.2552542...   \n",
       "685  [0.40746984, 0.45578644, 0.47212955, 0.4500661...   \n",
       "686  [0.31452677, 0.2739423, 0.29177672, 0.23973174...   \n",
       "687  [0.52647233, 0.50926405, 0.48760957, 0.5163718...   \n",
       "\n",
       "                                      chroma_features2  \\\n",
       "0    [0.2010815228001731, 0.17877661978133974, 0.13...   \n",
       "1    [0.31813983391072426, 0.3531293189845657, 0.28...   \n",
       "2    [0.2811999780220349, 0.3090476569723263, 0.313...   \n",
       "3    [0.2933080292151442, 0.2664511925875559, 0.244...   \n",
       "4    [0.38282826680034837, 0.3370629763078627, 0.25...   \n",
       "..                                                 ...   \n",
       "683  [0.365042918727885, 0.3005016817024467, 0.2271...   \n",
       "684  [0.2849922771460006, 0.24627764286685888, 0.20...   \n",
       "685  [0.29454657735332035, 0.27965101813545123, 0.2...   \n",
       "686  [0.31061829776123817, 0.2660416390428546, 0.27...   \n",
       "687  [0.38839065712295284, 0.3523226336215788, 0.33...   \n",
       "\n",
       "                                      chroma_features3  class_label  \n",
       "0    [0.41260996, 0.35917467, 0.3394772, 0.4229124,...            3  \n",
       "1    [0.620216, 0.6951215, 0.61286265, 0.61554337, ...            1  \n",
       "2    [0.5648398, 0.59924424, 0.63488513, 0.58711034...            3  \n",
       "3    [0.6027757, 0.57053393, 0.5303954, 0.58117336,...            3  \n",
       "4    [0.6155926, 0.56290025, 0.47744942, 0.41551587...            3  \n",
       "..                                                 ...          ...  \n",
       "683  [0.7129718, 0.5999869, 0.49596426, 0.4806125, ...            5  \n",
       "684  [0.51113725, 0.50479937, 0.39885342, 0.5197480...            4  \n",
       "685  [0.61592126, 0.5651262, 0.5621043, 0.5231517, ...            3  \n",
       "686  [0.62170583, 0.5375296, 0.56233233, 0.54323864...            4  \n",
       "687  [0.7167689, 0.7025457, 0.6690119, 0.6442276, 0...            4  \n",
       "\n",
       "[688 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "labels = [[i] for i in data['class_label']]\n",
    "# testLabels = [[i] for i in testData['class_label']]\n",
    "y_train = np.array(labels)\n",
    "# y_test = np.array(testLabels)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(data, np.array(labels), test_size=0.1, random_state = 127)\n",
    "# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def get_one_hot(y):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y_onehot = encoder.fit_transform(y)\n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_onehot_train = get_one_hot(y_train)\n",
    "# y_onehot_test = get_one_hot(y_test)\n",
    "# print(y_onehot_train.shape, y_onehot_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X):\n",
    "    # normalize the features\n",
    "    X = (X - X.mean()) / X.std()\n",
    "    \n",
    "    # compute the covariance matrix\n",
    "    X = np.matrix(X)\n",
    "    cov = (X.T * X) / X.shape[0]\n",
    "    \n",
    "    # perform SVD\n",
    "    U, S, V = np.linalg.svd(cov)\n",
    "    \n",
    "    return U, S, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_data(X, U, k):\n",
    "    U_reduced = U[:,:k]\n",
    "    return np.dot(X, U_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_data(Z, U, k):\n",
    "    U_reduced = U[:,:k]\n",
    "    return np.dot(Z, U_reduced.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# აქ გვინდა რომ ყველა ფიჩერზე გვქონდეს წვდომა და მაგიტომ ამოღებისას უნდა შევცვალოთ როგორცაა შენახული დანარჩენი არაფრის შეცვლა არ მოგვიწევს"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_X(x):\n",
    "    X = x.drop(columns=['class_label'])\n",
    "    X = X.values\n",
    "    ls = [] #featurebi gvinda da magitom\n",
    "    for i in range(X.shape[0]):\n",
    "        features = []\n",
    "        for j in range(X.shape[1]):\n",
    "            for k in X[i][j]:\n",
    "                features.append(k)\n",
    "        ls.append(features)\n",
    "    res = np.array(ls)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_train = get_processed_X(data)\n",
    "# ls_test = get_processed_X(x_test)\n",
    "# print(ls_train.shape, ls_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 400\n",
    "U, S, V = pca(ls_train)\n",
    "ls_train = project_data(ls_train, U, k)\n",
    "# U1, S1, V1 = pca(ls_test)\n",
    "# ls_test = project_data(ls_test, U, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # ნეირონული ქსელის კოდი"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def softmax(z):\n",
    "    z_exp = [math.exp(i) for i in z]\n",
    "    sum_z_exp = sum(z_exp)\n",
    "    return [i / sum_z_exp for i in z_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    z3 = a2 * theta2.T\n",
    "    h = []\n",
    "    for i in range(z3.shape[0]):\n",
    "        z = [z3[i, j] for j in range(z3.shape[1])]\n",
    "        h.append(softmax(z))\n",
    "    h = np.array(h)\n",
    "#     h = sigmoid(z3)\n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "\n",
    "#     J = (-1 / m) * np.sum(y * np.log(h).T) #softmax\n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    J = cost(params,input_size, hidden_size, num_labels, X, y, learning_rate)\n",
    "\n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # add the gradient regularization term\n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 118), (5, 26))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = ls_train.shape[1]\n",
    "hidden_size = 25\n",
    "num_labels = y_onehot_train.shape[1]\n",
    "learning_rate = 1\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "m = ls_train.shape[0]\n",
    "ls_train = np.matrix(ls_train)\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17247922 0.28789608 0.14883344 0.12546897 0.2653223 ]\n",
      " [0.17241979 0.28794842 0.14883973 0.12550678 0.26528528]\n",
      " [0.17192533 0.28863002 0.14884698 0.12585387 0.2647438 ]\n",
      " ...\n",
      " [0.16935671 0.29224183 0.14871209 0.12761853 0.26207085]\n",
      " [0.17227469 0.28818    0.148826   0.12560841 0.26511089]\n",
      " [0.17247871 0.28789585 0.14883471 0.12547132 0.2653194 ]]\n",
      "2.5771617268364184\n"
     ]
    }
   ],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(ls_train, theta1, theta2)\n",
    "a1.shape, z2.shape, a2.shape, z3.shape, h.shape\n",
    "print(h)\n",
    "print(cost(params, input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5771617268364184, (3080,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 1.0892041513527524\n",
       "     jac: array([-0.00069153, -0.4754602 , -0.04605256, ..., -0.00281459,\n",
       "       -0.00148521,  0.00168297])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 500\n",
       "     nit: 64\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([-0.10506967,  0.00430652,  0.09777166, ...,  0.52999959,\n",
       "        0.3128878 , -0.53126736])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate), \n",
    "                method='TNC', jac=True, options={'maxiter': 500})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_train = np.matrix(ls_train)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(ls_train, theta1, theta2)\n",
    "y_pred_train = np.array(np.argmax(h, axis=1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = []\n",
    "thetas.append(theta1)\n",
    "thetas.append(theta2)\n",
    "np.save('weights', thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_test = np.matrix(ls_test)\n",
    "\n",
    "# a1, z2, a2, z3, h = forward_propagate(ls_test, theta1, theta2)\n",
    "# y_pred = np.array(np.argmax(h, axis=1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8284883720930233\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred_train, y_train)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y_test)]\n",
    "# accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
