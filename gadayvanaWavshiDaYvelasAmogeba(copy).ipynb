{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ყველა ფაილის მისამართის ამოღება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.7.2)\n",
      "Requirement already satisfied: six>=1.3 in /home/tamar/.local/lib/python3.7/site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (2.1.8)\n",
      "Requirement already satisfied: numba>=0.43.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.47.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.21.3)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: joblib>=0.12 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.17.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied: llvmlite>=0.31.0dev0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
      "Requirement already satisfied: setuptools in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (41.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/tamar/.local/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa) (1.12.3)\n",
      "Requirement already satisfied: pycparser in /home/tamar/.local/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n",
      "Requirement already satisfied: pydub in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio ფაილების გადაყვანა wav-ში"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(files):\n",
    "    for src in files:\n",
    "        dst = src[:-3] + \"wav\"\n",
    "        s = AudioSegment.from_file(src)\n",
    "        s.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folders = os.listdir('data')\n",
    "for sub_dir in folders:\n",
    "#     print(sub_dir)\n",
    "    mp3_files = glob.glob(os.getcwd() + '/data/' + sub_dir + '/*.mp3')\n",
    "    convert_to_wav(mp3_files)\n",
    "#     m4a_files = glob.glob(os.getcwd() + '/data/' + '2' + '/*.m4a')\n",
    "#     mp4_files = glob.glob(os.getcwd() + '/data/' + '2' + '/*.mp4')\n",
    "#     aac_files = glob.glob(os.getcwd() + '/data/' + '2' + '/*.aac')\n",
    "#     files = mp3_files + m4a_files + mp4_files + aac_files\n",
    "#     რატომღაც ამას არ შვება :(\n",
    "#     convert_to_wav(files) \n",
    "#     print(mp3_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color =green>extract_features ვარგა. ქვემოთ რაც წერია ყველაფერს სწორად შვება</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = get_mfcc(audio, sample_rate)\n",
    "        zero_crossing_rate = get_zero_crossing_rate(audio)\n",
    "#         other features\n",
    "        return [mfccs, zero_crossing_rate]\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features():\n",
    "    folders = os.listdir('data')\n",
    "    folders.sort()\n",
    "    all_features = []\n",
    "    for label, sub_dir in enumerate(folders): #label {0; 4}\n",
    "        for file_name in glob.glob(os.getcwd() + '/data/' + sub_dir + '/*.wav'):\n",
    "#             print(\"Extracting file \", file_name)\n",
    "            try:\n",
    "                features = get_features(file_name)\n",
    "            except Exception as e:\n",
    "                print(\"Extraction error\")\n",
    "                continue\n",
    "            all_features.append(features +  [label + 1])\n",
    "    data = pd.DataFrame(all_features, columns=['mfccs', 'zero_crossing_rate' , 'class_label'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(audio, sr):\n",
    "    #Mel Frequency Cepstral Coefficient\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "    mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "#     mfccs - (40, 61), mfccsscaled - (40,)\n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_crossing_rate(audio):\n",
    "    #ZERO_CROSSING_RATE\n",
    "    rate = librosa.feature.zero_crossing_rate(audio)\n",
    "#     rate - (1, 61)\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_centroid(audio):\n",
    "    #SPECTRAL_CENTROID\n",
    "    sp = librosa.feature.spectral_centroid(audio)\n",
    "#     sp - (1, 61)\n",
    "    return sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_roll_ff(audio, sr):\n",
    "    # Spectral-roll off\n",
    "    S, phase = librosa.magphase(librosa.stft(audio))\n",
    "    a = librosa.feature.spectral_rolloff(S=S, sr=sr)\n",
    "#     a - (1, 61)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_flux(audio, sr):\n",
    "    # Spectral flux\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "#     onset_env - (61,)\n",
    "    return onset_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma_features(audio, sr):    \n",
    "    # Chroma features (needs scaling)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr) #N1\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio, sr=sr) #Chroma energy normalized statistics\n",
    "    chroma_cq = librosa.feature.chroma_cqt(y=audio, sr=sr)\n",
    "#     samive - (12, 61)\n",
    "    return [chroma_stft, chroma_cens, chroma_cq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(audio, sr):\n",
    "    # Pitch (needs scaling)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)\n",
    "#     pitches - (1025, 61)\n",
    "    return pitches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = get_all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariam/anaconda3/envs/ml/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/mariam/anaconda3/envs/ml/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "data = get_all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfccs</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-485.77536, 103.56779, 5.1006136, 12.516183, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-293.36374, 99.50089, 54.90203, 52.981934, 21...</td>\n",
       "      <td>[[0.00244140625, 0.0048828125, 0.00732421875, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-491.02005, 118.41104, 11.42216, 14.3336115, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-440.54318, 48.62018, -13.115458, 39.109562, ...</td>\n",
       "      <td>[[0.19384765625, 0.28369140625, 0.39306640625,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[-369.51532, 71.60074, 18.153286, 36.65747, 5....</td>\n",
       "      <td>[[0.02294921875, 0.05078125, 0.0634765625, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>[-333.4615, 78.47683, -11.2027025, 34.041134, ...</td>\n",
       "      <td>[[0.0, 0.01953125, 0.10400390625, 0.138671875,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>[-361.54678, 111.94943, 69.74507, 25.497889, 1...</td>\n",
       "      <td>[[0.1123046875, 0.11767578125, 0.1279296875, 0...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>[-260.16925, 111.11569, 54.97757, 40.923706, 1...</td>\n",
       "      <td>[[0.12548828125, 0.130859375, 0.1357421875, 0....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>[-257.8959, 84.435715, -3.2791898, 42.858597, ...</td>\n",
       "      <td>[[0.0, 0.0595703125, 0.10205078125, 0.13330078...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>[-448.94565, 54.668053, 7.428348, 14.600398, -...</td>\n",
       "      <td>[[0.15185546875, 0.2001953125, 0.21533203125, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mfccs  \\\n",
       "0    [-485.77536, 103.56779, 5.1006136, 12.516183, ...   \n",
       "1    [-293.36374, 99.50089, 54.90203, 52.981934, 21...   \n",
       "2    [-491.02005, 118.41104, 11.42216, 14.3336115, ...   \n",
       "3    [-440.54318, 48.62018, -13.115458, 39.109562, ...   \n",
       "4    [-369.51532, 71.60074, 18.153286, 36.65747, 5....   \n",
       "..                                                 ...   \n",
       "140  [-333.4615, 78.47683, -11.2027025, 34.041134, ...   \n",
       "141  [-361.54678, 111.94943, 69.74507, 25.497889, 1...   \n",
       "142  [-260.16925, 111.11569, 54.97757, 40.923706, 1...   \n",
       "143  [-257.8959, 84.435715, -3.2791898, 42.858597, ...   \n",
       "144  [-448.94565, 54.668053, 7.428348, 14.600398, -...   \n",
       "\n",
       "                                    zero_crossing_rate  class_label  \n",
       "0    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1  \n",
       "1    [[0.00244140625, 0.0048828125, 0.00732421875, ...            1  \n",
       "2    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            1  \n",
       "3    [[0.19384765625, 0.28369140625, 0.39306640625,...            1  \n",
       "4    [[0.02294921875, 0.05078125, 0.0634765625, 0.0...            1  \n",
       "..                                                 ...          ...  \n",
       "140  [[0.0, 0.01953125, 0.10400390625, 0.138671875,...            5  \n",
       "141  [[0.1123046875, 0.11767578125, 0.1279296875, 0...            5  \n",
       "142  [[0.12548828125, 0.130859375, 0.1357421875, 0....            5  \n",
       "143  [[0.0, 0.0595703125, 0.10205078125, 0.13330078...            5  \n",
       "144  [[0.15185546875, 0.2001953125, 0.21533203125, ...            5  \n",
       "\n",
       "[145 rows x 3 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariam/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "labels = [[i] for i in data['class_label']]\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(labels)\n",
    "print(y_onehot.shape)\n",
    "y =np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# აქ გვინდა რომ ყველა ფიჩერზე გვქონდეს წვდომა და მაგიტომ ამოღებისას უნდა შევცვალოთ როგორცაა შენახული დანარჩენი არაფრის შეცვლა არ მოგვიწევს"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 40)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=['class_label', 'zero_crossing_rate'])\n",
    "X = X.values\n",
    "X[0][0].shape\n",
    "# X\n",
    "# type(X[0][0])\n",
    "ls = [] #featurebi gvinda da magitom\n",
    "for i in range(X.shape[0]):\n",
    "    ls.append(X[i][0])\n",
    "ls = np.array(ls)\n",
    "ls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # ნეირონული ქსელის კოდი"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "#     print(z.shape) \n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    z3 = a2 * theta2.T\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 41), (5, 26))"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = ls.shape[1]\n",
    "hidden_size = 25\n",
    "num_labels = y_onehot.shape[1]\n",
    "learning_rate = 1\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "m = ls.shape[0]\n",
    "ls = np.matrix(ls)\n",
    "y = np.matrix(y_onehot)\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145, 41), (145, 25), (145, 26), (145, 5), (145, 5))"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(ls, theta1, theta2)\n",
    "a1.shape, z2.shape, a2.shape, z3.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    # compute the cost\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # add the gradient regularization term\n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.5102641414287357, (1155,))"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, ls, y_onehot, learning_rate)\n",
    "J, grad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 1.833400293399364\n",
       "     jac: array([-0.00128446,  0.59556136, -0.10624242, ...,  0.01653273,\n",
       "        0.01965055, -0.00125899])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 250\n",
       "     nit: 29\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([-0.08518204, -0.02837108, -0.04215426, ..., -0.27492505,\n",
       "        0.10382888, -0.18255394])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size, num_labels, ls, y_onehot, learning_rate), \n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [5],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [2],\n",
       "       [5],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [5],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [2],\n",
       "       [5],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [5],\n",
       "       [4],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = np.matrix(ls)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(ls, theta1, theta2)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
