{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ყველა ფაილის მისამართის ამოღება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.7.2)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.21.3)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.47.0)\n",
      "Requirement already satisfied: joblib>=0.12 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.14.0)\n",
      "Requirement already satisfied: six>=1.3 in /home/tamar/.local/lib/python3.7/site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (2.1.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.17.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/tamar/.local/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa) (1.12.3)\n",
      "Requirement already satisfied: setuptools in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (41.2.0)\n",
      "Requirement already satisfied: llvmlite>=0.31.0dev0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
      "Requirement already satisfied: pycparser in /home/tamar/.local/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pydub in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.23.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio ფაილების გადაყვანა wav-ში"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color =green>extract_features ვარგა. ქვემოთ რაც წერია ყველაფერს სწორად შვება</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = get_mfcc(audio, sample_rate)\n",
    "#         zero_crossing_rate = get_zero_crossing_rate(audio)\n",
    "#         spectral_features = get_spectral_features(audio, sample_rate)\n",
    "        chroma_features = get_chroma_features(audio, sample_rate)\n",
    "#         other features\n",
    "#         return [mfccs, zero_crossing_rate] + spectral_features + chroma_features\n",
    "        return [mfccs]\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(folder):\n",
    "    folders = os.listdir(folder)\n",
    "    folders.sort()\n",
    "    all_features = []\n",
    "    for label, sub_dir in enumerate(folders): #label {0; 4}\n",
    "        for file_name in glob.glob(os.getcwd() + '/' + folder +'/' + sub_dir + '/*.wav'):\n",
    "#             print(\"Extracting file \", file_name)\n",
    "            try:\n",
    "                features = get_features(file_name)\n",
    "            except Exception as e:\n",
    "                print(\"Extraction error\")\n",
    "                continue\n",
    "            all_features.append(features +  [label + 1])\n",
    "#     data = pd.DataFrame(all_features, columns=['mfccs', 'zero_crossing_rate', 'spectral_features[0]', 'spectral_features[1]', 'spectral_features[2]',  'chroma_features[0]','chroma_features[1]', 'chroma_features[2]', 'class_label'])\n",
    "    data = pd.DataFrame(all_features, columns=['mfccs', 'class_label'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(audio, sr):\n",
    "    #Mel Frequency Cepstral Coefficient\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "    mfccs_scaled = np.mean(mfccs.T,axis=0)\n",
    "#     mfccs - (40, სხვადასხვა), mfccsscaled - (40,)\n",
    "    return mfccs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_crossing_rate(audio):\n",
    "    #ZERO_CROSSING_RATE\n",
    "    rate = librosa.feature.zero_crossing_rate(audio)\n",
    "    rate_scaled = np.mean(rate.T,axis=0)\n",
    "#     rate - (1, სხვადასხვა)\n",
    "    return rate_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_features(audio, sr):\n",
    "    sp = librosa.feature.spectral_centroid(audio)\n",
    "    S, phase = librosa.magphase(librosa.stft(audio))\n",
    "    a = librosa.feature.spectral_rolloff(S=S, sr=sr)\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "    onset_env.shape = (onset_env.shape[0], 1)\n",
    "    sp_scaled = np.mean(sp.T,axis=0)\n",
    "    a_scaled = np.mean(a.T,axis=0)\n",
    "    onset_env_scaled = np.mean(onset_env,axis=0)\n",
    "    return [sp_scaled, a_scaled, onset_env_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma_features(audio, sr):    \n",
    "    # Chroma features (needs scaling)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr) #N1\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio, sr=sr) #Chroma energy normalized statistics\n",
    "    chroma_cq = librosa.feature.chroma_cqt(y=audio, sr=sr)\n",
    "#     samive - (12, სხვადასხვა)\n",
    "    chroma_stft_scaled = np.mean(chroma_stft.T,axis=0)\n",
    "    chroma_cens_scaled = np.mean(chroma_cens.T,axis=0)\n",
    "    chroma_cq_scaled = np.mean(chroma_cq.T,axis=0)\n",
    "    return [chroma_stft_scaled, chroma_cens_scaled, chroma_cq_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(audio, sr):\n",
    "    # Pitch (needs scaling)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)\n",
    "#     pitches - (1025, სხვადასხვა)\n",
    "    pitches_scaled = np.mean(pitches.T,axis=0)\n",
    "    return pitches_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_all_features('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfccs</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-375.04742, 71.76099, -9.058271, 58.62941, -2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-602.8608, 40.34575, 19.960438, 24.787498, 6....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-551.16956, 59.801514, -0.14260375, 24.958803...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-512.303, 39.143753, -3.8368192, 26.026289, 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[-583.33325, 23.309853, 2.6051655, 16.292341, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>[-428.7131, 72.103806, 8.8743925, 34.941143, 1...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>684</td>\n",
       "      <td>[-505.51352, 74.166504, 19.460085, 22.2807, -2...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685</td>\n",
       "      <td>[-353.27307, 102.400566, 6.734233, 49.48563, -...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>686</td>\n",
       "      <td>[-622.4822, 107.89334, 3.9235218, 20.481346, 0...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>687</td>\n",
       "      <td>[-608.07245, 55.75549, 13.409108, 26.613298, -...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mfccs  class_label\n",
       "0    [-375.04742, 71.76099, -9.058271, 58.62941, -2...            1\n",
       "1    [-602.8608, 40.34575, 19.960438, 24.787498, 6....            1\n",
       "2    [-551.16956, 59.801514, -0.14260375, 24.958803...            1\n",
       "3    [-512.303, 39.143753, -3.8368192, 26.026289, 1...            1\n",
       "4    [-583.33325, 23.309853, 2.6051655, 16.292341, ...            1\n",
       "..                                                 ...          ...\n",
       "683  [-428.7131, 72.103806, 8.8743925, 34.941143, 1...            5\n",
       "684  [-505.51352, 74.166504, 19.460085, 22.2807, -2...            5\n",
       "685  [-353.27307, 102.400566, 6.734233, 49.48563, -...            5\n",
       "686  [-622.4822, 107.89334, 3.9235218, 20.481346, 0...            5\n",
       "687  [-608.07245, 55.75549, 13.409108, 26.613298, -...            5\n",
       "\n",
       "[688 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619, 2) (69, 2) (619, 1) (69, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "labels = [[i] for i in data['class_label']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, np.array(labels), test_size=0.1, random_state = 127)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def get_one_hot(y):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y_onehot = encoder.fit_transform(y)\n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619, 5) (69, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_onehot_train = get_one_hot(y_train)\n",
    "y_onehot_test = get_one_hot(y_test)\n",
    "print(y_onehot_train.shape, y_onehot_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# აქ გვინდა რომ ყველა ფიჩერზე გვქონდეს წვდომა და მაგიტომ ამოღებისას უნდა შევცვალოთ როგორცაა შენახული დანარჩენი არაფრის შეცვლა არ მოგვიწევს"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_X(x):\n",
    "    X = x.drop(columns=['class_label'])\n",
    "    X = X.values\n",
    "    ls = [] #featurebi gvinda da magitom\n",
    "    for i in range(X.shape[0]):\n",
    "        features = []\n",
    "        for j in range(X.shape[1]):\n",
    "            for k in X[i][j]:\n",
    "                features.append(k)\n",
    "        ls.append(features)\n",
    "    res = np.array(ls)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619, 40) (69, 40)\n"
     ]
    }
   ],
   "source": [
    "ls_train = get_processed_X(x_train)\n",
    "ls_test = get_processed_X(x_test)\n",
    "print(ls_train.shape, ls_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # ნეირონული ქსელის კოდი"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def softmax(z):\n",
    "    z_exp = [math.exp(i) for i in z]\n",
    "    sum_z_exp = sum(z_exp)\n",
    "    return [i / sum_z_exp for i in z_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    z3 = a2 * theta2.T\n",
    "    h = []\n",
    "    for i in range(z3.shape[0]):\n",
    "        z = [z3[i, j] for j in range(z3.shape[1])]\n",
    "        h.append(softmax(z))\n",
    "    h = np.array(h)\n",
    "#     h = sigmoid(z3)\n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "\n",
    "#     J = (-1 / m) * np.sum(y * np.log(h).T) #softmax\n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    J = cost(params,input_size, hidden_size, num_labels, X, y, learning_rate)\n",
    "\n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # add the gradient regularization term\n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 41), (5, 26))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = ls_train.shape[1]\n",
    "hidden_size = 25\n",
    "num_labels = y_onehot_train.shape[1]\n",
    "learning_rate = 1\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "m = ls_train.shape[0]\n",
    "ls_train = np.matrix(ls_train)\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28754724 0.14424646 0.25488318 0.22312675 0.09019637]\n",
      " [0.28134257 0.14555026 0.25241203 0.22803542 0.09265972]\n",
      " [0.28307371 0.14379572 0.25262825 0.2287861  0.09171621]\n",
      " ...\n",
      " [0.27859901 0.14364651 0.2507537  0.23360173 0.09339905]\n",
      " [0.28047743 0.1442734  0.25180215 0.23071275 0.09273426]\n",
      " [0.2945373  0.14436087 0.25742944 0.21618313 0.08748925]]\n",
      "2.5906122853542723\n"
     ]
    }
   ],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(ls_train, theta1, theta2)\n",
    "a1.shape, z2.shape, a2.shape, z3.shape, h.shape\n",
    "print(h)\n",
    "print(cost(params, input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5906122853542723, (1155,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 1.7344200416738422\n",
       "     jac: array([-1.33121816e-07, -6.24516522e-05, -8.36702166e-05, ...,\n",
       "       -3.15494328e-03, -3.24853279e-03, -3.05937101e-03])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 250\n",
       "     nit: 30\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([ 0.02610821, -0.05529028, -0.04455745, ...,  0.02456713,\n",
       "       -0.03244276,  0.08405872])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate), \n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_train = np.matrix(ls_train)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(ls_train, theta1, theta2)\n",
    "y_pred_train = np.array(np.argmax(h, axis=1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_test = np.matrix(ls_test)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(ls_test, theta1, theta2)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5767366720516963\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred_train, y_train)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4492753623188406\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y_test)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
