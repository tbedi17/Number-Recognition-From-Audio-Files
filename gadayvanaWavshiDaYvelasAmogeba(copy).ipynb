{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ყველა ფაილის მისამართის ამოღება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.7.2)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.21.3)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.47.0)\n",
      "Requirement already satisfied: joblib>=0.12 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (0.14.0)\n",
      "Requirement already satisfied: six>=1.3 in /home/tamar/.local/lib/python3.7/site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (2.1.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from librosa) (1.17.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/tamar/.local/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa) (1.12.3)\n",
      "Requirement already satisfied: setuptools in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (41.2.0)\n",
      "Requirement already satisfied: llvmlite>=0.31.0dev0 in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
      "Requirement already satisfied: pycparser in /home/tamar/.local/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pydub in /home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages (0.23.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio ფაილების გადაყვანა wav-ში"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav(files):\n",
    "    for src in files:\n",
    "        dst = src[:-3] + \"wav\"\n",
    "        s = AudioSegment.from_file(src)\n",
    "        s.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folders = os.listdir('data')\n",
    "for sub_dir in folders:\n",
    "#     print(sub_dir)\n",
    "    mp3_files = glob.glob(os.getcwd() + '/data/' + sub_dir + '/*.mp3')\n",
    "    convert_to_wav(mp3_files)\n",
    "#     m4a_files = glob.glob(os.getcwd() + '/data/' + '2' + '/*.m4a')\n",
    "#     mp4_files = glob.glob(os.getcwd() + '/data/' + '2' + '/*.mp4')\n",
    "#     aac_files = glob.glob(os.getcwd() + '/data/' + '2' + '/*.aac')\n",
    "#     files = mp3_files + m4a_files + mp4_files + aac_files\n",
    "#     რატომღაც ამას არ შვება :(\n",
    "#     convert_to_wav(files) \n",
    "#     print(mp3_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color =green>extract_features ვარგა. ქვემოთ რაც წერია ყველაფერს სწორად შვება</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = get_mfcc(audio, sample_rate)\n",
    "        zero_crossing_rate = get_zero_crossing_rate(audio)\n",
    "#         chroma_features = get_chroma_features(audio, sample_rate)\n",
    "#         other features\n",
    "#         return [mfccs, zero_crossing_rate] + chroma_features\n",
    "        return [mfccs, zero_crossing_rate]\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(folder):\n",
    "    folders = os.listdir(folder)\n",
    "    folders.sort()\n",
    "    all_features = []\n",
    "    for label, sub_dir in enumerate(folders): #label {0; 4}\n",
    "        for file_name in glob.glob(os.getcwd() + '/' + folder +'/' + sub_dir + '/*.wav'):\n",
    "#             print(\"Extracting file \", file_name)\n",
    "            try:\n",
    "                features = get_features(file_name)\n",
    "            except Exception as e:\n",
    "                print(\"Extraction error\")\n",
    "                continue\n",
    "            all_features.append(features +  [label + 1])\n",
    "#     data = pd.DataFrame(all_features, columns=['mfccs', 'zero_crossing_rate', 'chroma_features[0]','chroma_features[1]', 'chroma_features[2]', 'class_label'])\n",
    "    data = pd.DataFrame(all_features, columns=['mfccs', 'zero_crossing_rate', 'class_label'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(audio, sr):\n",
    "    #Mel Frequency Cepstral Coefficient\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "    mfccs_scaled = np.mean(mfccs.T,axis=0)\n",
    "#     mfccs - (40, სხვადასხვა), mfccsscaled - (40,)\n",
    "    return mfccs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_crossing_rate(audio):\n",
    "    #ZERO_CROSSING_RATE\n",
    "    rate = librosa.feature.zero_crossing_rate(audio)\n",
    "    rate_scaled = np.mean(rate.T,axis=0)\n",
    "#     rate - (1, სხვადასხვა)\n",
    "    return rate_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_centroid(audio):\n",
    "    #SPECTRAL_CENTROID\n",
    "    sp = librosa.feature.spectral_centroid(audio)\n",
    "    sp_scaled = np.mean(sp.T,axis=0)\n",
    "#     sp - (1, სხვადასხვა)\n",
    "    return sp_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_roll_ff(audio, sr):\n",
    "    # Spectral-roll off\n",
    "    S, phase = librosa.magphase(librosa.stft(audio))\n",
    "    a = librosa.feature.spectral_rolloff(S=S, sr=sr)\n",
    "    a_scaled = np.mean(a.T,axis=0)\n",
    "#     a - (1, სხვადასხვა)\n",
    "    return a_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_flux(audio, sr):\n",
    "    # Spectral flux\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "    onset_env.shape = (onset_env.shape[0], 1)\n",
    "    onset_env_scaled = np.mean(onset_env,axis=0)\n",
    "#     onset_env - (სხვადასხვა,1)\n",
    "    return onset_env_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma_features(audio, sr):    \n",
    "    # Chroma features (needs scaling)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr) #N1\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio, sr=sr) #Chroma energy normalized statistics\n",
    "    chroma_cq = librosa.feature.chroma_cqt(y=audio, sr=sr)\n",
    "#     samive - (12, სხვადასხვა)\n",
    "    chroma_stft_scaled = np.mean(chroma_stft.T,axis=0)\n",
    "    chroma_cens_scaled = np.mean(chroma_cens.T,axis=0)\n",
    "    chroma_cq_scaled = np.mean(chroma_cq.T,axis=0)\n",
    "    return [chroma_stft_scaled, chroma_cens_scaled, chroma_cq_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch(audio, sr):\n",
    "    # Pitch (needs scaling)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)\n",
    "#     pitches - (1025, სხვადასხვა)\n",
    "    pitches_scaled = np.mean(pitches.T,axis=0)\n",
    "    return pitches_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_all_features('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfccs</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[-340.99185, 71.76349, -9.056803, 58.628418, -...</td>\n",
       "      <td>[0.13918022260273974]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-549.25867, 23.328505, 2.6170156, 16.299675, ...</td>\n",
       "      <td>[0.3345120337701613]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-576.85846, 15.04707, -0.45508817, 13.05824, ...</td>\n",
       "      <td>[0.35200980659965037]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-373.90222, 69.62015, 38.59025, 51.163128, 9....</td>\n",
       "      <td>[0.07336795691287878]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[-485.77536, 103.56779, 5.1006126, 12.516183, ...</td>\n",
       "      <td>[0.046856037621359224]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>[-428.0815, 65.607445, -6.0010858, 17.54062, -...</td>\n",
       "      <td>[0.1625384706439394]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>[-259.54175, 97.03256, -4.835197, 36.80339, -2...</td>\n",
       "      <td>[0.10187725981404959]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>[-526.5556, 111.043015, 11.877811, 17.914228, ...</td>\n",
       "      <td>[0.028998013200431036]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>[-368.36838, 79.430695, 18.874813, 32.134174, ...</td>\n",
       "      <td>[0.07103794642857143]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>[-519.13727, 42.85378, -10.486978, 16.277979, ...</td>\n",
       "      <td>[0.28955078125]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mfccs  \\\n",
       "0    [-340.99185, 71.76349, -9.056803, 58.628418, -...   \n",
       "1    [-549.25867, 23.328505, 2.6170156, 16.299675, ...   \n",
       "2    [-576.85846, 15.04707, -0.45508817, 13.05824, ...   \n",
       "3    [-373.90222, 69.62015, 38.59025, 51.163128, 9....   \n",
       "4    [-485.77536, 103.56779, 5.1006126, 12.516183, ...   \n",
       "..                                                 ...   \n",
       "161  [-428.0815, 65.607445, -6.0010858, 17.54062, -...   \n",
       "162  [-259.54175, 97.03256, -4.835197, 36.80339, -2...   \n",
       "163  [-526.5556, 111.043015, 11.877811, 17.914228, ...   \n",
       "164  [-368.36838, 79.430695, 18.874813, 32.134174, ...   \n",
       "165  [-519.13727, 42.85378, -10.486978, 16.277979, ...   \n",
       "\n",
       "         zero_crossing_rate  class_label  \n",
       "0     [0.13918022260273974]            1  \n",
       "1      [0.3345120337701613]            1  \n",
       "2     [0.35200980659965037]            1  \n",
       "3     [0.07336795691287878]            1  \n",
       "4    [0.046856037621359224]            1  \n",
       "..                      ...          ...  \n",
       "161    [0.1625384706439394]            5  \n",
       "162   [0.10187725981404959]            5  \n",
       "163  [0.028998013200431036]            5  \n",
       "164   [0.07103794642857143]            5  \n",
       "165         [0.28955078125]            5  \n",
       "\n",
       "[166 rows x 3 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 3) (34, 3) (132, 1) (34, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "labels = [[i] for i in data['class_label']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, np.array(labels), test_size=0.2, random_state = 127)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def get_one_hot(y):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    y_onehot = encoder.fit_transform(y)\n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5) (34, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/tamar/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_onehot_train = get_one_hot(y_train)\n",
    "y_onehot_test = get_one_hot(y_test)\n",
    "print(y_onehot_train.shape, y_onehot_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# აქ გვინდა რომ ყველა ფიჩერზე გვქონდეს წვდომა და მაგიტომ ამოღებისას უნდა შევცვალოთ როგორცაა შენახული დანარჩენი არაფრის შეცვლა არ მოგვიწევს"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_X(x):\n",
    "    X = x.drop(columns=['class_label'])\n",
    "    X = X.values\n",
    "    ls = [] #featurebi gvinda da magitom\n",
    "    for i in range(X.shape[0]):\n",
    "        features = []\n",
    "        for j in range(X.shape[1]):\n",
    "            for k in X[i][j]:\n",
    "                features.append(k)\n",
    "        ls.append(features)\n",
    "    res = np.array(ls)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 41) (34, 41)\n"
     ]
    }
   ],
   "source": [
    "ls_train = get_processed_X(x_train)\n",
    "ls_test = get_processed_X(x_test)\n",
    "print(ls_train.shape, ls_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # ნეირონული ქსელის კოდი"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    z3 = a2 * theta2.T\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 42), (5, 26))"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = ls_train.shape[1]\n",
    "hidden_size = 25\n",
    "num_labels = y_onehot_train.shape[1]\n",
    "learning_rate = 0.1\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "m = ls_train.shape[0]\n",
    "ls_train = np.matrix(ls_train)\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132, 42), (132, 25), (132, 26), (132, 5), (132, 5))"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(ls_train, theta1, theta2)\n",
    "a1.shape, z2.shape, a2.shape, z3.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    # compute the cost\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # add the gradient regularization term\n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6698525468479475, (1180,))"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 1.573547037860539\n",
       "     jac: array([ 2.11144712e-08,  4.25791495e-05,  4.89281383e-05, ...,\n",
       "       -1.68370391e-03, -1.58347896e-03, -5.48618581e-05])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 250\n",
       "     nit: 39\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([ 0.00751297,  0.06307461,  0.06212658, ..., -0.56982676,\n",
       "       -0.43751032, -0.07241006])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size, num_labels, ls_train, y_onehot_train, learning_rate), \n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_train = np.matrix(ls_train)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(ls_train, theta1, theta2)\n",
    "y_pred_train = np.array(np.argmax(h, axis=1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_test = np.matrix(ls_test)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(ls_test, theta1, theta2)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred_train, y_train)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4411764705882353\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y_test)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "mfccs (learning rate = 1) = (40% - 50%)\n",
    "mfccs + zero_crossing (lr = 1) = (~64%)\n",
    "mfccs + zero_crossing + spectral_centroid = (~44%)\n",
    "mfccs + zero_crossing + spectral_roll_ff = (~38%)\n",
    "mfccs + zero_crossing + spectral_flux = (~23%)\n",
    "mfccs + zero_crossing + chroma_features (~58%, ~87%(training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
